{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T07:59:50.707488Z",
     "iopub.status.busy": "2021-04-12T07:59:50.706702Z",
     "iopub.status.idle": "2021-04-12T07:59:53.360233Z",
     "shell.execute_reply": "2021-04-12T07:59:53.359779Z"
    },
    "papermill": {
     "duration": 2.688706,
     "end_time": "2021-04-12T07:59:53.360375",
     "exception": false,
     "start_time": "2021-04-12T07:59:50.671669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax version 0.4.1\n",
      "Flax version 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import flax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "\n",
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print('Jax version', jax.__version__)\n",
    "print('Flax version', flax.__version__)\n",
    "random_key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import squeeze, unsqueeze\n",
    "from layers import Split\n",
    "from layers import ActNorm, Conv1x1, AffineCoupling\n",
    "\n",
    "from model import FlowStep, GLOW\n",
    "\n",
    "from utils import summarize_jax_model\n",
    "from utils import plot_image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d10f2c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:37.420299Z",
     "iopub.status.busy": "2021-04-12T08:00:37.419774Z",
     "iopub.status.idle": "2021-04-12T08:00:37.423966Z",
     "shell.execute_reply": "2021-04-12T08:00:37.423550Z"
    },
    "papermill": {
     "duration": 0.046074,
     "end_time": "2021-04-12T08:00:37.424075",
     "exception": false,
     "start_time": "2021-04-12T08:00:37.378001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def get_logpz(z, priors):\n",
    "    logpz = 0\n",
    "    for zi, priori in zip(z, priors):\n",
    "        if priori is None:\n",
    "            logsigma = jnp.zeros(zi.shape)\n",
    "        else:\n",
    "            mu, logsigma = jnp.split(priori, 2, axis=-1)\n",
    "        logpz += jnp.sum(- logsigma - 0.5 * jnp.log(2 * jnp.pi) \n",
    "                         - 0.5 * (zi - mu) ** 2 / jnp.exp(2 * logsigma))\n",
    "    return logpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:37.661637Z",
     "iopub.status.busy": "2021-04-12T08:00:37.660763Z",
     "iopub.status.idle": "2021-04-12T08:00:37.666168Z",
     "shell.execute_reply": "2021-04-12T08:00:37.667212Z"
    },
    "papermill": {
     "duration": 0.075107,
     "end_time": "2021-04-12T08:00:37.667428",
     "exception": false,
     "start_time": "2021-04-12T08:00:37.592321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_fn(image_path, num_bits=5, size=256, training=True):\n",
    "    \"\"\"Read image file, quantize and map to [-0.5, 0.5] range.\n",
    "    If num_bits = 8, there is no quantization effect.\"\"\"\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(image_path))\n",
    "    # Resize input image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (size, size))\n",
    "    image = tf.clip_by_value(image, 0., 255.)\n",
    "    # Discretize to the given number of bits\n",
    "    if num_bits < 8:\n",
    "        image = tf.floor(image / 2 ** (8 - num_bits))\n",
    "    # Send to [-1, 1]\n",
    "    num_bins = 2 ** num_bits\n",
    "    image = image / num_bins - 0.5\n",
    "    if training:\n",
    "        image = image + tf.random.uniform(tf.shape(image), 0, 1. / num_bins)\n",
    "    return image\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def postprocess(x, num_bits):\n",
    "    \"\"\"Map [-0.5, 0.5] quantized images to uint space\"\"\"\n",
    "    num_bins = 2 ** num_bits\n",
    "    x = jnp.floor((x + 0.5) * num_bins)\n",
    "    x *= 256. / num_bins\n",
    "    return jnp.clip(x, 0, 255).astype(jnp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:37.914685Z",
     "iopub.status.busy": "2021-04-12T08:00:37.913855Z",
     "iopub.status.idle": "2021-04-12T08:00:37.936242Z",
     "shell.execute_reply": "2021-04-12T08:00:37.937190Z"
    },
    "papermill": {
     "duration": 0.093191,
     "end_time": "2021-04-12T08:00:37.937406",
     "exception": false,
     "start_time": "2021-04-12T08:00:37.844215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(model, \n",
    "           params, \n",
    "           eps=None, \n",
    "           shape=None, \n",
    "           sampling_temperature=1.0, \n",
    "           key=jax.random.PRNGKey(0),\n",
    "           postprocess_fn=None, \n",
    "           save_path=None,\n",
    "           display=True):\n",
    "    \"\"\"Sampling only requires a call to the reverse pass of the model\"\"\"\n",
    "    if eps is None:\n",
    "        zL = jax.random.normal(key, shape) \n",
    "    else: \n",
    "        zL = eps[-1]\n",
    "    y, *_ = model.apply(params, zL, eps=eps, sampling_temperature=sampling_temperature, reverse=True)\n",
    "    if postprocess_fn is not None:\n",
    "        y = postprocess_fn(y)\n",
    "    plot_image_grid(y, save_path=save_path, display=display,\n",
    "                    title=None if save_path is None else save_path.rsplit('.', 1)[0].rsplit('/', 1)[-1])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047292,
     "end_time": "2021-04-12T08:00:38.044841",
     "exception": false,
     "start_time": "2021-04-12T08:00:37.997549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:38.144987Z",
     "iopub.status.busy": "2021-04-12T08:00:38.143697Z",
     "iopub.status.idle": "2021-04-12T08:00:38.148071Z",
     "shell.execute_reply": "2021-04-12T08:00:38.147580Z"
    },
    "papermill": {
     "duration": 0.066409,
     "end_time": "2021-04-12T08:00:38.148201",
     "exception": false,
     "start_time": "2021-04-12T08:00:38.081792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_glow(train_ds,\n",
    "               val_ds=None,\n",
    "               num_samples=9,\n",
    "               image_size=256,\n",
    "               num_channels=3,\n",
    "               num_bits=5,\n",
    "               init_lr=1e-3,\n",
    "               num_epochs=1,\n",
    "               num_sample_epochs=1,\n",
    "               num_warmup_epochs=10,\n",
    "               num_save_epochs=1,\n",
    "               steps_per_epoch=1,\n",
    "               K=32,\n",
    "               L=3,\n",
    "               nn_width=512,\n",
    "               sampling_temperature=0.7,\n",
    "               learn_top_prior=True,\n",
    "               key=jax.random.PRNGKey(0),\n",
    "               **kwargs):\n",
    "    \"\"\"Simple training loop.\n",
    "    Args:\n",
    "        train_ds: Training dataset iterator (e.g. tensorflow dataset)\n",
    "        val_ds: Validation dataset (optional)\n",
    "        num_samples: Number of samples to generate at each epoch\n",
    "        image_size: Input image size\n",
    "        num_channels: Number of channels in input images\n",
    "        num_bits: Number of bits for discretization\n",
    "        init_lr: Initial learning rate (Adam)\n",
    "        num_epochs: Numer of training epochs\n",
    "        num_sample_epochs: Visualize sample at this interval\n",
    "        num_warmup_epochs: Linear warmup of the learning rate to init_lr\n",
    "        num_save_epochs: save mode at this interval\n",
    "        steps_per_epochs: Number of steps per epochs\n",
    "        K: Number of flow iterations in the GLOW model\n",
    "        L: number of scales in the GLOW model\n",
    "        nn_width: Layer width in the Affine Coupling Layer\n",
    "        sampling_temperature: Smoothing temperature for sampling from the \n",
    "            Gaussian priors (1 = no effect)\n",
    "        learn_top_prior: Whether to learn the prior for highest latent variable zL.\n",
    "            Otherwise, assumes standard unit Gaussian prior\n",
    "        key: Random seed\n",
    "    \"\"\"\n",
    "    del kwargs\n",
    "    # Init model\n",
    "    model = GLOW(K=K,\n",
    "                 L=L, \n",
    "                 nn_width=nn_width, \n",
    "                 learn_top_prior=learn_top_prior,\n",
    "                 key=key)\n",
    "    \n",
    "    # Init optimizer and learning rate schedule\n",
    "    params = model.init(random_key, next(train_ds))\n",
    "    opt = flax.optim.Adam(learning_rate=init_lr).create(params)\n",
    "    \n",
    "    def lr_warmup(step):\n",
    "        return init_lr * jnp.minimum(1., step / (num_warmup_epochs * steps_per_epoch + 1e-8))\n",
    "    \n",
    "    # Helper functions for training\n",
    "    bits_per_dims_norm = np.log(2.) * num_channels * image_size**2\n",
    "    @jax.jit\n",
    "    def get_logpx(z, logdets, priors):\n",
    "        logpz = get_logpz(z, priors)\n",
    "        logpz = jnp.mean(logpz) / bits_per_dims_norm        # bits per dimension normalization\n",
    "        logdets = jnp.mean(logdets) / bits_per_dims_norm\n",
    "        logpx = logpz + logdets - num_bits                  # num_bits: dequantization factor\n",
    "        return logpx, logpz, logdets\n",
    "        \n",
    "    @jax.jit\n",
    "    def train_step(opt, batch):\n",
    "        def loss_fn(params):\n",
    "            _, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "            logpx, logpz, logdets = get_logpx(z, logdets, priors)\n",
    "            return - logpx, (logpz, logdets)\n",
    "        logs, grad = jax.value_and_grad(loss_fn, has_aux=True)(opt.target)\n",
    "        opt = opt.apply_gradient(grad, learning_rate=lr_warmup(opt.state.step))\n",
    "        return logs, opt\n",
    "    \n",
    "    # Helper functions for evaluation \n",
    "    @jax.jit\n",
    "    def eval_step(params, batch):\n",
    "        _, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "        return - get_logpx(z, logdets, priors)[0]\n",
    "    \n",
    "    # Helper function for sampling from random latent fixed during training for comparison\n",
    "    eps = []\n",
    "    if not os.path.exists(\"samples\"): os.makedirs(\"samples\")\n",
    "    if not os.path.exists(\"weights\"): os.makedirs(\"weights\")\n",
    "    for i in range(L):\n",
    "        expected_h = image_size // 2**(i + 1)\n",
    "        expected_c = num_channels * 2**(i + 1)\n",
    "        if i == L - 1: expected_c *= 2\n",
    "        eps.append(jax.random.normal(key, (num_samples, expected_h, expected_h, expected_c)))\n",
    "    sample_fn = partial(sample, eps=eps, key=key, display=False,\n",
    "                        sampling_temperature=sampling_temperature,\n",
    "                        postprocess_fn=partial(postprocess, num_bits=num_bits))\n",
    "    \n",
    "    # Train\n",
    "    print(\"Start training...\")\n",
    "    print(\"Available jax devices:\", jax.devices())\n",
    "    print()\n",
    "    bits = 0.\n",
    "    start = time.time()\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            # train\n",
    "            for i in range(steps_per_epoch):\n",
    "                batch = next(train_ds)\n",
    "                loss, opt = train_step(opt, batch)\n",
    "                print(f\"\\r\\033[92m[Epoch {epoch + 1}/{num_epochs}]\\033[0m\"\n",
    "                      f\"\\033[93m[Batch {i + 1}/{steps_per_epoch}]\\033[0m\"\n",
    "                      f\" loss = {loss[0]:.5f},\"\n",
    "                      f\" (log(p(z)) = {loss[1][0]:.5f},\"\n",
    "                      f\" logdet = {loss[1][1]:.5f})\", end='')\n",
    "                if np.isnan(loss[0]):\n",
    "                    print(\"\\nModel diverged - NaN loss\")\n",
    "                    return None, None\n",
    "                \n",
    "                step = epoch * steps_per_epoch + i + 1\n",
    "                if step % int(num_sample_epochs * steps_per_epoch) == 0:\n",
    "                    sample_fn(model, opt.target, \n",
    "                              save_path=f\"samples/step_{step:05d}.png\")\n",
    "\n",
    "            # eval on one batch of validation samples \n",
    "            # + generate random sample\n",
    "            t = time.time() - start\n",
    "            if val_ds is not None:\n",
    "                bits = eval_step(opt.target, next(val_ds))\n",
    "            print(f\"\\r\\033[92m[Epoch {epoch + 1}/{num_epochs}]\\033[0m\"\n",
    "                  f\"[{int(t // 3600):02d}h {int((t % 3600) // 60):02d}mn]\"\n",
    "                  f\" train_bits/dims = {loss[0]:.3f},\"\n",
    "                  f\" val_bits/dims = {bits:.3f}\" + \" \" * 50)\n",
    "            \n",
    "            # Save parameters\n",
    "            if (epoch + 1) % num_save_epochs == 0 or epoch == num_epochs - 1:\n",
    "                with open(f'weights/model_epoch={epoch + 1:03d}.weights', 'wb') as f:\n",
    "                    f.write(flax.serialization.to_bytes(opt.target))\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nInterrupted by user at epoch {epoch + 1}\")\n",
    "        \n",
    "    # returns final model and parameters\n",
    "    return model, opt.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035548,
     "end_time": "2021-04-12T08:00:38.219427",
     "exception": false,
     "start_time": "2021-04-12T08:00:38.183879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note on multi-devices training:** To extend the code for training on multi-devices we can make use of the `jax.vmap` operator (parallelize across XLA devices) instead of `jax.jit`, we also need to share the current parameters with all the devices (use `flax.jax_utils.replicate` on the optimizer before training), and finally to split the data across the devices, which can be handled with the `tf.data` in the input pipeline. [There is a more complete tutorial with an example here](https://flax.readthedocs.io/en/stable/howtos/ensembling.html)\n",
    "\n",
    "# Experiments\n",
    "\n",
    "**Note:** the current model was trained in a Kaggle notebook, with some computation restrictions: Therefore it was run for 12 epochs due to time limits (roughly 40k training steps) + smaller flow depth (K = 16 instead of 32) to fit into single GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:38.296525Z",
     "iopub.status.busy": "2021-04-12T08:00:38.295903Z",
     "iopub.status.idle": "2021-04-12T08:00:38.300025Z",
     "shell.execute_reply": "2021-04-12T08:00:38.299597Z"
    },
    "papermill": {
     "duration": 0.045839,
     "end_time": "2021-04-12T08:00:38.300130",
     "exception": false,
     "start_time": "2021-04-12T08:00:38.254291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data hyperparameters for 1 GPU training\n",
    "# Some small changes to the original model so \n",
    "# everything fits in memory\n",
    "# In particular, I had  to use shallower\n",
    "# flows (smaller K value)\n",
    "config_dict = {\n",
    "    'image_path': \"../lfw/lfw-deepfunneled/lfw-deepfunneled\",\n",
    "    'train_split': 0.7,\n",
    "    'image_size': 32,\n",
    "    'num_channels': 3,\n",
    "    'num_bits': 8, ##changed from 5 to 8\n",
    "    'batch_size': 4,\n",
    "    'K': 16,\n",
    "    'L': 3,\n",
    "    'nn_width': 512, \n",
    "    'learn_top_prior': True,\n",
    "    'sampling_temperature': 0.7,\n",
    "    'init_lr': 1e-3,\n",
    "    'num_epochs': 13,\n",
    "    'num_warmup_epochs': 1,\n",
    "    'num_sample_epochs': 0.2, # Fractional epochs for sampling because one epoch is quite long \n",
    "    'num_save_epochs': 5,\n",
    "}\n",
    "\n",
    "output_hw = config_dict[\"image_size\"] // 2 ** config_dict[\"L\"]\n",
    "output_c = config_dict[\"num_channels\"] * 4**config_dict[\"L\"] // 2**(config_dict[\"L\"] - 1)\n",
    "config_dict[\"sampling_shape\"] = (output_hw, output_hw, output_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034909,
     "end_time": "2021-04-12T08:00:38.369926",
     "exception": false,
     "start_time": "2021-04-12T08:00:38.335017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:38.450229Z",
     "iopub.status.busy": "2021-04-12T08:00:38.449717Z",
     "iopub.status.idle": "2021-04-12T08:00:42.747434Z",
     "shell.execute_reply": "2021-04-12T08:00:42.746356Z"
    },
    "papermill": {
     "duration": 4.341473,
     "end_time": "2021-04-12T08:00:42.747579",
     "exception": false,
     "start_time": "2021-04-12T08:00:38.406106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "def get_train_dataset(image_path, image_size, num_bits, batch_size, skip=None, **kwargs):\n",
    "    del kwargs\n",
    "    train_ds = tf.data.Dataset.list_files(f\"{image_path}/*/*.jpg\")\n",
    "    if skip is not None:\n",
    "        train_ds = train_ds.skip(skip)\n",
    "    train_ds = train_ds.shuffle(buffer_size=20000)\n",
    "    train_ds = train_ds.map(partial(map_fn, size=image_size, num_bits=num_bits, training=True))\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = train_ds.repeat()\n",
    "    return iter(tfds.as_numpy(train_ds))\n",
    "\n",
    "\n",
    "def get_val_dataset(image_path, image_size, num_bits, batch_size, \n",
    "                    take=None, repeat=False, **kwargs):\n",
    "    del kwargs\n",
    "    val_ds = tf.data.Dataset.list_files(f\"{image_path}/*/*.jpg\")\n",
    "    if take is not None:\n",
    "        val_ds = val_ds.take(take)\n",
    "    val_ds = val_ds.map(partial(map_fn, size=image_size, num_bits=num_bits, training=False))\n",
    "    val_ds = val_ds.batch(batch_size)\n",
    "    if repeat:\n",
    "        val_ds = val_ds.repeat()\n",
    "    return iter(tfds.as_numpy(val_ds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a9d9511",
   "metadata": {},
   "source": [
    "## Einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7c2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Einops\n",
    "import numpy as np\n",
    "\n",
    "from PIL.Image import fromarray\n",
    "from IPython import get_ipython\n",
    "\n",
    "\n",
    "def display_np_arrays_as_images():\n",
    "    def np_to_png(a):\n",
    "        if 2 <= len(a.shape) <= 3:\n",
    "            return fromarray(np.array(np.clip(a, 0, 1) * 255, dtype='uint8'))._repr_png_()\n",
    "        else:\n",
    "            return fromarray(np.zeros([1, 1], dtype='uint8'))._repr_png_()\n",
    "\n",
    "    def np_to_text(obj, p, cycle):\n",
    "        if len(obj.shape) < 2:\n",
    "            print(repr(obj))\n",
    "        if 2 <= len(obj.shape) <= 3:\n",
    "            pass\n",
    "        else:\n",
    "            print('<array of shape {}>'.format(obj.shape))\n",
    "\n",
    "    get_ipython().display_formatter.formatters['image/png'].for_type(np.ndarray, np_to_png)\n",
    "    get_ipython().display_formatter.formatters['text/plain'].for_type(np.ndarray, np_to_text)\n",
    "\n",
    "\n",
    "from IPython.display import display_html\n",
    "\n",
    "_style_inline = \"\"\"<style>\n",
    ".einops-answer {\n",
    "    color: transparent;\n",
    "    padding: 5px 15px;\n",
    "    background-color: #def;\n",
    "}\n",
    ".einops-answer:hover { color: blue; } \n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def guess(x):\n",
    "    display_html(\n",
    "        _style_inline\n",
    "        + \"<h4>Answer is: <span class='einops-answer'>{x}</span> (hover to see)</h4>\".format(x=tuple(x)),\n",
    "        raw=True)\n",
    "        \n",
    "import einops\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "display_np_arrays_as_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3867ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233 training images\n",
      "3308 training steps per epoch\n",
      "CPU times: total: 14.2 s\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_images = len(glob.glob(f\"{config_dict['image_path']}/*/*.jpg\"))\n",
    "config_dict['steps_per_epoch'] = num_images // config_dict['batch_size']\n",
    "train_split = int(config_dict['train_split'] * num_images)\n",
    "print(f\"{num_images} training images\")\n",
    "print(f\"{config_dict['steps_per_epoch']} training steps per epoch\")\n",
    "\n",
    "#Train data\n",
    "train_ds = get_train_dataset(**config_dict, skip=train_split)\n",
    "\n",
    "# Val data\n",
    "# During training we'll only evaluate on one batch of validation \n",
    "# to save on computations\n",
    "val_ds = get_val_dataset(**config_dict, take=config_dict['batch_size'], repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "##WIP\n",
    "test_image = \"../lfw/lfw-deepfunneled/lfw-deepfunneled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T08:00:42.826328Z",
     "iopub.status.busy": "2021-04-12T08:00:42.825817Z",
     "iopub.status.idle": "2021-04-12T08:04:23.819752Z",
     "shell.execute_reply": "2021-04-12T08:04:23.819259Z"
    },
    "papermill": {
     "duration": 221.035393,
     "end_time": "2021-04-12T08:04:23.819876",
     "exception": false,
     "start_time": "2021-04-12T08:00:42.784483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233 training images\n",
      "3308 training steps per epoch\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.5 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "plot_image_grid(postprocess(next(val_ds), num_bits=config_dict['num_bits'])[:25], \n",
    "                 title=\"Input data sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050374,
     "end_time": "2021-04-12T08:04:23.921997",
     "exception": false,
     "start_time": "2021-04-12T08:04:23.871623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T08:04:24.028734Z",
     "iopub.status.busy": "2021-04-12T08:04:24.027676Z",
     "iopub.status.idle": "2021-04-12T15:39:55.159329Z",
     "shell.execute_reply": "2021-04-12T15:39:55.158849Z"
    },
    "papermill": {
     "duration": 27331.188753,
     "end_time": "2021-04-12T15:39:55.161143",
     "exception": false,
     "start_time": "2021-04-12T08:04:23.972390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\optim\\base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Available jax devices: [CpuDevice(id=0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\core\\scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\core\\scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n",
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\optim\\base.py:90: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  params_flat, treedef = jax.tree_flatten(params)\n",
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\optim\\base.py:97: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  new_params = jax.tree_unflatten(treedef, new_params_flat)\n",
      "c:\\Users\\cupca\\Anaconda3\\envs\\jax_nf\\lib\\site-packages\\flax\\optim\\base.py:98: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  new_param_states = jax.tree_unflatten(treedef, new_states_flat)\n"
     ]
    }
   ],
   "source": [
    "model, params = train_glow(train_ds, val_ds=val_ds, **config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:40:17.509218Z",
     "iopub.status.busy": "2021-04-12T15:40:17.487573Z",
     "iopub.status.idle": "2021-04-12T15:40:19.576687Z",
     "shell.execute_reply": "2021-04-12T15:40:19.577117Z"
    },
    "papermill": {
     "duration": 13.307516,
     "end_time": "2021-04-12T15:40:19.577280",
     "exception": false,
     "start_time": "2021-04-12T15:40:06.269764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Random samples evolution during training\")\n",
    "from PIL import Image\n",
    "\n",
    "# filepaths\n",
    "fp_in = \"samples/step_*.png\"\n",
    "fp_out = \"sample_evolution.gif\"\n",
    "\n",
    "# https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#gif\n",
    "img, *imgs = [Image.open(f) for f in sorted(glob.glob(fp_in))]\n",
    "img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
    "         save_all=True, duration=200, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<img src=\"sample_evolution.gif\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 11.044445,
     "end_time": "2021-04-12T15:40:42.182704",
     "exception": false,
     "start_time": "2021-04-12T15:40:31.138259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T15:41:04.692240Z",
     "iopub.status.busy": "2021-04-12T15:41:04.691691Z",
     "iopub.status.idle": "2021-04-12T15:41:04.696459Z",
     "shell.execute_reply": "2021-04-12T15:41:04.696011Z"
    },
    "papermill": {
     "duration": 11.601025,
     "end_time": "2021-04-12T15:41:04.696574",
     "exception": false,
     "start_time": "2021-04-12T15:40:53.095549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional, example code to load trained weights\n",
    "if False:\n",
    "    model = GLOW(K=config_dict['K'],\n",
    "                 L=config_dict['L'], \n",
    "                 nn_width=config_dict['nn_width'], \n",
    "                 learn_top_prior=config_dict['learn_top_prior'])\n",
    "\n",
    "    with open('weights/model_epoch=100.weights', 'rb') as f:\n",
    "        params = model.init(random_key, jnp.zeros((config_dict['batch_size'],\n",
    "                                                     config_dict['image_size'],\n",
    "                                                     config_dict['image_size'],\n",
    "                                                     config_dict['num_channels'])))\n",
    "        params = flax.serialization.from_bytes(params, f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T15:41:26.786697Z",
     "iopub.status.busy": "2021-04-12T15:41:26.784842Z",
     "iopub.status.idle": "2021-04-12T15:41:26.787285Z",
     "shell.execute_reply": "2021-04-12T15:41:26.787698Z"
    },
    "papermill": {
     "duration": 10.929332,
     "end_time": "2021-04-12T15:41:26.787834",
     "exception": false,
     "start_time": "2021-04-12T15:41:15.858502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct(model, params, batch):\n",
    "    global config_dict\n",
    "    x, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "    rec, *_ = model.apply(params, z[-1], z=z, reverse=True)\n",
    "    rec = postprocess(rec, config_dict[\"num_bits\"])\n",
    "    plot_image_grid(postprocess(batch, config_dict[\"num_bits\"]), title=\"original\")\n",
    "    plot_image_grid(rec, title=\"reconstructions\")\n",
    "    \n",
    "\n",
    "def interpolate(model, params, batch, num_samples=16):\n",
    "    global config_dict\n",
    "    i1, i2 = np.random.choice(range(batch.shape[0]), size=2, replace=False)\n",
    "    in_ = np.stack([batch[i1], batch[i2]], axis=0)\n",
    "    x, z, logdets, priors = model.apply(params, in_, reverse=False)\n",
    "    # interpolate\n",
    "    interpolated_z = []\n",
    "    for zi in z:\n",
    "        z_1, z_2 = zi[:2]\n",
    "        interpolate = jnp.array([t * z_1 + (1 - t) * z_2 for t in np.linspace(0., 1., 16)])\n",
    "        interpolated_z.append(interpolate)\n",
    "    rec, *_ = model.apply(params, interpolated_z[-1], z=interpolated_z, reverse=True)\n",
    "    rec = postprocess(rec, config_dict[\"num_bits\"])\n",
    "    plot_image_grid(rec, title=\"Linear interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 11.020073,
     "end_time": "2021-04-12T15:41:49.314696",
     "exception": false,
     "start_time": "2021-04-12T15:41:38.294623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reconstructions\n",
    "As a sanity check let's first look at image reconstructions: since the model is invertible these should always be perfect, up to small float errors, except in very bad cases e.g. NaN values or other numerical errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:42:11.633001Z",
     "iopub.status.busy": "2021-04-12T15:42:11.631913Z",
     "iopub.status.idle": "2021-04-12T15:42:35.692850Z",
     "shell.execute_reply": "2021-04-12T15:42:35.693257Z"
    },
    "papermill": {
     "duration": 35.522545,
     "end_time": "2021-04-12T15:42:35.693418",
     "exception": false,
     "start_time": "2021-04-12T15:42:00.170873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(val_ds)\n",
    "reconstruct(model, params, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 11.034127,
     "end_time": "2021-04-12T15:42:58.315209",
     "exception": false,
     "start_time": "2021-04-12T15:42:47.281082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sampling\n",
    "Now let's take some random samples from the model, at different sampling temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:43:21.066831Z",
     "iopub.status.busy": "2021-04-12T15:43:21.052362Z",
     "iopub.status.idle": "2021-04-12T15:43:34.220551Z",
     "shell.execute_reply": "2021-04-12T15:43:34.221280Z"
    },
    "papermill": {
     "duration": 24.878295,
     "end_time": "2021-04-12T15:43:34.221512",
     "exception": false,
     "start_time": "2021-04-12T15:43:09.343217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample(model, params, shape=(16,) + config_dict[\"sampling_shape\"],  key=random_key,\n",
    "       postprocess_fn=partial(postprocess, num_bits=config_dict[\"num_bits\"]),\n",
    "       save_path=\"samples/final_random_sample_T=1.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:43:56.835211Z",
     "iopub.status.busy": "2021-04-12T15:43:56.834215Z",
     "iopub.status.idle": "2021-04-12T15:44:01.855209Z",
     "shell.execute_reply": "2021-04-12T15:44:01.855708Z"
    },
    "papermill": {
     "duration": 16.114872,
     "end_time": "2021-04-12T15:44:01.855880",
     "exception": false,
     "start_time": "2021-04-12T15:43:45.741008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample(model, params, shape=(16,) + config_dict[\"sampling_shape\"], \n",
    "       key=jax.random.PRNGKey(1), sampling_temperature=0.7,\n",
    "       postprocess_fn=partial(postprocess, num_bits=config_dict[\"num_bits\"]),\n",
    "       save_path=\"samples/final_random_sample_T=0.7.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:44:24.635263Z",
     "iopub.status.busy": "2021-04-12T15:44:24.634313Z",
     "iopub.status.idle": "2021-04-12T15:44:30.377588Z",
     "shell.execute_reply": "2021-04-12T15:44:30.378026Z"
    },
    "papermill": {
     "duration": 17.285687,
     "end_time": "2021-04-12T15:44:30.378182",
     "exception": false,
     "start_time": "2021-04-12T15:44:13.092495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample(model, params, shape=(16,) + config_dict[\"sampling_shape\"], \n",
    "       key=jax.random.PRNGKey(2), sampling_temperature=0.7,\n",
    "       postprocess_fn=partial(postprocess, num_bits=config_dict[\"num_bits\"]),\n",
    "       save_path=\"samples/final_random_sample_T=0.7.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:44:53.199929Z",
     "iopub.status.busy": "2021-04-12T15:44:53.198719Z",
     "iopub.status.idle": "2021-04-12T15:44:58.692393Z",
     "shell.execute_reply": "2021-04-12T15:44:58.692847Z"
    },
    "papermill": {
     "duration": 17.088802,
     "end_time": "2021-04-12T15:44:58.692989",
     "exception": false,
     "start_time": "2021-04-12T15:44:41.604187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample(model, params, shape=(16,) + config_dict[\"sampling_shape\"], \n",
    "       key=jax.random.PRNGKey(3), sampling_temperature=0.5,\n",
    "       postprocess_fn=partial(postprocess, num_bits=config_dict[\"num_bits\"]),\n",
    "       save_path=\"samples/final_random_sample_T=0.5.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 11.667376,
     "end_time": "2021-04-12T15:45:21.581232",
     "exception": false,
     "start_time": "2021-04-12T15:45:09.913856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Latent space\n",
    "Finally, we can look at the linear interpolation in the learned latent space: We generate embedding $z_1$ and $z_2$ by feeding two validation set images to Glow. Then we plot the decoded images for latent vectors $t + z_1 + (1 - t) z_2$ for $t \\in [0, 1]$ (at all level of the latent hierarchy).\n",
    "\n",
    "**Note on conditional modeling**  The model can also be extented to conditional generation (in the original code this is done by (i) learning the top prior from one-hot class embedding rather than all zeros input, and (ii) adding a small classifier on top of the output latent which should aim at predicting the correct class).\n",
    "\n",
    "In the original paper, this allows them to do \"semantic manipulation\" on the Celeba dataset by building representative centroid vectors for different attributes/classes (e.g.g $z_{smiling}$ and $z_{non-smiling}$). They can use then use the vector direction $z_{smiling}$ - $z_{non-smiling}$ as a guide to browse the latent space (in that example, to make images more or less \"smiling\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:45:43.843367Z",
     "iopub.status.busy": "2021-04-12T15:45:43.842441Z",
     "iopub.status.idle": "2021-04-12T15:46:01.569716Z",
     "shell.execute_reply": "2021-04-12T15:46:01.570167Z"
    },
    "papermill": {
     "duration": 28.882994,
     "end_time": "2021-04-12T15:46:01.570316",
     "exception": false,
     "start_time": "2021-04-12T15:45:32.687322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpolate(model, params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-12T15:46:23.837424Z",
     "iopub.status.busy": "2021-04-12T15:46:23.836605Z",
     "iopub.status.idle": "2021-04-12T15:46:31.996989Z",
     "shell.execute_reply": "2021-04-12T15:46:31.996494Z"
    },
    "papermill": {
     "duration": 19.295457,
     "end_time": "2021-04-12T15:46:31.997107",
     "exception": false,
     "start_time": "2021-04-12T15:46:12.701650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpolate(model, params, batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28036.31319,
   "end_time": "2021-04-12T15:46:48.892318",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-12T07:59:32.579128",
   "version": "2.3.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0acd1efabb006334362d5539cf634a5caec85a558927fcfefa2918e6e757f5d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
